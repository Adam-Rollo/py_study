{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.keras import datasets   # 我们使用这个函数来下载数据\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170450944/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "trainSet, testSet = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarModel(object):    \n",
    "    def __init__(self, lr, batch_size, iter_num):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.iter_num = iter_num\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.y = tf.placeholder(tf.int32, [None, 10])        \n",
    "        self.dropRate = tf.placeholder(tf.float32)                    \n",
    " \n",
    "        conv1 = tf.layers.conv2d(self.X, 32, 5, padding='same', activation=tf.nn.relu,\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.0001, seed=0),\n",
    "                                     bias_initializer=tf.constant_initializer(0.001))        \n",
    "        pool1 = tf.layers.max_pooling2d(conv1 , 3, 2, padding='same')           \n",
    "        conv2 = tf.layers.conv2d(pool1, 32, 5, padding='same', activation=tf.nn.relu,\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.01, seed=0),\n",
    "                                     bias_initializer=tf.constant_initializer(0.001))\n",
    "        pool2 = tf.layers.average_pooling2d(conv2, 3,2, padding='same')          \n",
    "        conv3 = tf.layers.conv2d(pool2, 64, 5, padding='same', activation=tf.nn.relu,\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.01, seed=0),\n",
    "                                     bias_initializer=tf.constant_initializer(0.001))\n",
    "        pool3 = tf.layers.average_pooling2d(conv3, 3,2, padding='same')  \n",
    "\n",
    "        flatten = tf.reshape(pool3 , [self.batch_size, 4*4*64])\n",
    "        dense1 = tf.layers.dense(flatten, 64,  activation=tf.nn.relu, use_bias=True,\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.01, seed=0),\n",
    "                                 bias_initializer=tf.constant_initializer(0.001))      \n",
    "        dense1 = tf.nn.dropout(dense1, self.dropRate)\n",
    "        dense2 = tf.layers.dense(dense1, 10, use_bias=True,\n",
    "                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.01, seed=0),\n",
    "                                 bias_initializer=tf.constant_initializer(0.1))  \n",
    "        \n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.y, logits=dense2)\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss )        \n",
    "\n",
    "        # 用于模型训练\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.y, axis=1), tf.argmax(dense2, axis=1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        # 用于保存训练好的模型\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        summary_loss = tf.summary.scalar('loss', self.loss)\n",
    "        summary_accuracy = tf.summary.scalar('accuracy', self.accuracy)\n",
    "        self.merged_summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    def get_next_train_batch(self):        \n",
    "        m = 0\n",
    "        while True:\n",
    "            batch_x = trainSet[0][m:m+self.batch_size]\n",
    "            batch_y = trainSet[1][m:m+self.batch_size]\n",
    "\n",
    "            m += self.batch_size\n",
    "            if m+self.batch_size > 50000:\n",
    "                m=0\n",
    "            yield batch_x, (np.arange(10) == batch_y[:, None]).astype(int).reshape(self.batch_size,10)\n",
    "        \n",
    "            \n",
    "    def get_next_test_batch(self):        \n",
    "        n = 0\n",
    "        while True:\n",
    "            batch_x = testSet[0][n:n+self.batch_size]\n",
    "            batch_y = testSet[1][n:n+self.batch_size]\n",
    "\n",
    "            n += self.batch_size\n",
    "            if n+self.batch_size > 10000:\n",
    "                n=0\n",
    "            yield batch_x, (np.arange(10) == batch_y[:, None]).astype(int).reshape(self.batch_size,10)\n",
    "            \n",
    "    def train(self):\n",
    "        \n",
    "        with tf.Session() as sess:            #  打开一个会话。可以想象成浏览器打开一个标签页一样，直观地理解一下\n",
    "            sess.run(tf.global_variables_initializer())  # 先初始化所有变量。\n",
    "            generator = self.get_next_train_batch()  # 读取一批数据\n",
    "            genetator_test = self.get_next_test_batch()\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter('log/train_base', sess.graph)\n",
    "            summary_writer_test = tf.summary.FileWriter('log/test_base')\n",
    "            \n",
    "            for i in range(self.iter_num):\n",
    "                batch_x, batch_y = generator.next()                  \n",
    "                loss, _= sess.run([self.loss, self.train_step], feed_dict={self.X: batch_x, self.y: batch_y, self.dropRate:0.5})   # 每调用一次sess.run，就像拧开水管一样，所有self.loss和self.train_step涉及到的运算都会被调用一次。\n",
    "                \n",
    "                if i%1000 == 0:  \n",
    "                    batch_x, batch_y = generator.next()             \n",
    "                    train_accuracy, summary_str = sess.run([self.accuracy, self.merged_summary_op], feed_dict={self.X: batch_x, self.y: batch_y, self.dropRate:1.})  # 把训练集数据装填进去\n",
    "                    summary_writer.add_summary(summary_str, i)                    \n",
    "                    test_x, test_y = genetator_test.next()\n",
    "                    test_accuracy, summary_str = sess.run([self.accuracy, self.merged_summary_op], feed_dict={self.X: test_x, self.y: test_y, self.dropRate:1.})   # 把测试集数据装填进去\n",
    "                    summary_writer_test.add_summary(summary_str, i)\n",
    "                    print ('iter\\t%i\\tloss\\t%f\\ttrain_accuracy\\t%f\\ttest_accuracy\\t%f' % (i,loss,train_accuracy,test_accuracy))\n",
    "            self.saver.save(sess, 'model/cifarModel') # 保存模型\n",
    "            summary_writer.flush()\n",
    "            summary_writer_test.flush()\n",
    "            \n",
    "    def test(self):\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess, 'model/cifarModel')\n",
    "            genetator_test = self.get_next_test_batch()\n",
    "            \n",
    "            Accuracy = []\n",
    "            for i in range(int(10000 / self.batch_size)):\n",
    "                test_x, test_y = genetator_test.next()\n",
    "                test_accuracy = sess.run(self.accuracy, feed_dict={self.X: test_x, self.y: test_y,self.dropRate:1.0})\n",
    "                Accuracy.append(test_accuracy)\n",
    "            print( '==' * 15)\n",
    "            print( 'Test Accuracy: ', np.mean(np.array(Accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
