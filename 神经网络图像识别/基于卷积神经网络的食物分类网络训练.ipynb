{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\molly\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import nets\n",
    "slim = tf.contrib.slim\n",
    "import numpy as np\n",
    "\n",
    "# 本文涉及到一个数据集food-101，出处为：https://www.vision.ee.ethz.ch/datasets_extra/food-101 。\n",
    "# 所涉及到的预训练文件resnet_v1_50.ckpt可以在https://github.com/tensorflow/models/tree/master/research/slim 下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res50(object):   \n",
    "    \n",
    "    def __init__(self, lr, batch_size, iter_num):\n",
    "        self.lr = lr   # 学习率\n",
    "        self.batch_size = batch_size\n",
    "        self.iter_num = iter_num   # 总共训练多少次\n",
    "        \n",
    "        tf.reset_default_graph()   # 重置图。有时候大家运行程序时候会提示某某tensor已经被构造。这是因为之前创建的图还在，然后重新运行一遍代码又创建了一个新图。可以在这里加一句tf.reset_default_graph()\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 101])   # 食物数据集有101个类\n",
    "        self.dropRate = tf.placeholder(tf.float32)\n",
    "        self.isTraining = tf.placeholder(tf.bool)\n",
    "        with slim.arg_scope(nets.resnet_v1.resnet_arg_scope()):\n",
    "            net, endpoints = nets.resnet_v1.resnet_v1_50(self.X, is_training=self.isTraining, num_classes=None)        \n",
    "            # 在这里，我们直接使用预置的模型。\n",
    "        net = tf.reshape(net , [-1, 2048])\n",
    "        # 下面这些，大家应该非常熟悉了，和MNIST的一样的\n",
    "        net = tf.nn.dropout(net, self.dropRate)\n",
    "        logits = tf.layers.dense(net, 101, use_bias=True,\n",
    "                                 kernel_initializer=tf.constant_initializer(0),\n",
    "                                 bias_initializer=tf.constant_initializer(0))\n",
    "        self.logits = logits\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.y, logits=logits)\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss)\n",
    "        \n",
    "        # 用于模型训练\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.y, axis=1), tf.argmax(logits, axis=1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        \n",
    "#         用于保存训练好的模型\n",
    "        self.saver = tf.train.Saver()\n",
    "    def read_image_label_list(self, class_file, data_file):\n",
    "        # 读取图像文件和标注列表\n",
    "        \n",
    "        img_list=[]\n",
    "        label_list=[]\n",
    "        class_dict = {}\n",
    "        \n",
    "        with open(class_file) as fr:\n",
    "            for i, line in enumerate(fr.readlines()):\n",
    "                class_dict[line.strip()] = i\n",
    "                \n",
    "        with open(data_file) as fr:\n",
    "            l = fr.readline()\n",
    "            while(l):\n",
    "                img_r = 'food-101/images/%s.jpg' % l.strip()\n",
    "                label_r = class_dict[l.split('/')[0]]\n",
    "                img_list.append(img_r)\n",
    "                label_list.append(int(label_r))\n",
    "                l = fr.readline()\n",
    "        return img_list, label_list    \n",
    "    def read_file(self,class_file, data_file):\n",
    "        image_list, label_list = self.read_image_label_list(class_file, data_file)\n",
    "        imagepaths, labels = tf.train.slice_input_producer([image_list, label_list], shuffle=True)\n",
    "        image = tf.read_file(imagepaths)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize_images(image, [224, 224])\n",
    "        image = (image * 1.0 / 127.5 - 1)\n",
    "        label = tf.one_hot(labels, 101)\n",
    "        X, Y = tf.train.batch([image, label], batch_size=self.batch_size, num_threads=2, capacity=self.batch_size*4)    \n",
    "        return X, Y\n",
    "    def train(self):\n",
    "        training_images, training_labels = self.read_file(r'food-101/meta/classes.txt',r'food-101/meta/train.txt')\n",
    "        test_images, test_labels = self.read_file(r'food-101/meta/classes.txt',r'food-101/meta/test.txt')\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)      \n",
    "            variables_to_restore = slim.get_variables_to_restore()\n",
    "            init_fn = slim.assign_from_checkpoint_fn(r'pre_trained/resnet_v1_50.ckpt',\n",
    "                                         variables_to_restore,\n",
    "                                         ignore_missing_vars=True)\n",
    "            init_fn(sess)\n",
    "            for i in range(self.iter_num):   \n",
    "                images, labels = sess.run([training_images, training_labels])       \n",
    "\n",
    "                feed_dict = {self.dropRate: 0.5,\n",
    "                         self.X :images,\n",
    "                         self.y :labels,\n",
    "                         self.isTraining:True}           \n",
    "\n",
    "                loss, _ = sess.run([self.loss, self.train_step], \n",
    "                                  feed_dict=feed_dict)   # 每调用一次sess.run，就像拧开水管一样，所有self.loss和self.train_step涉及到的运算都会被调用一次。\n",
    "                if i%100 == 0:   \n",
    "                    images, labels = sess.run([training_images, training_labels]) \n",
    "                    train_accuracy = sess.run(self.accuracy, feed_dict={self.X: images, self.y: labels, self.dropRate: 1., self.isTraining:True})  # 把训练集数据装填进去\n",
    "                    images, labels = sess.run([test_images, test_labels])\n",
    "                    test_accuracy = sess.run(self.accuracy, feed_dict={self.X: images, self.y: labels, self.dropRate: 1., self.isTraining:True})  # 把训练集数据装填进去\n",
    "                    \n",
    "                    print ('iter\\t%i\\tloss\\t%f\\ttrain_accuracy\\t%f\\ttest_accuracy\\t%f' % (i,loss,train_accuracy, test_accuracy))\n",
    "           \n",
    "            self.saver.save(sess, 'model/foodModel') # 保存模型                              \n",
    "             \n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    def test(self):\n",
    "        test_images, test_labels = self.read_file(r'food-101/meta/classes.txt',r'food-101/meta/test.txt')\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess, 'model/foodModel')\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)     \n",
    "            Accuracy = []\n",
    "            \n",
    "         \n",
    "            for i in range(int(25250/self.batch_size)):\n",
    "                images, labels = sess.run([test_images, test_labels])\n",
    "                test_accuracy = sess.run(self.accuracy, feed_dict={self.X: images, self.y: labels, self.dropRate: 1., self.isTraining:True})  # 把训练集数据装填进去\n",
    "                Accuracy.append(test_accuracy)\n",
    "\n",
    "            print('==' * 15) \n",
    "            print( 'Test Accuracy: ', np.mean(np.array(Accuracy))   ) \n",
    "            coord.request_stop()\n",
    "            coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Res50(0.1, 64, 10000)   # 学习率为0.1，每批传入64张图，训练10000次\n",
    "model.train()      # 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
