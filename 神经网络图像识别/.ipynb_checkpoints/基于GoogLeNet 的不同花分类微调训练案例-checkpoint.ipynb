{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import nets\n",
    "slim = tf.contrib.slim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(object):   \n",
    "    \n",
    "    def __init__(self, lr, batch_size, iter_num):\n",
    "        self.lr = lr   # 学习率\n",
    "        self.batch_size = batch_size\n",
    "        self.iter_num = iter_num   # 总共训练多少次\n",
    "        \n",
    "        tf.reset_default_graph()   # 重置图。有时候大家运行程序时候会提示某某tensor已经被构造。这是因为之前创建的图还在，然后重新运行一遍代码又创建了一个新图。可以在这里加一句tf.reset_default_graph()\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "        self.y = tf.placeholder(tf.float32, [None, 17])   # 17flowersu数据集有17个类\n",
    "        self.dropRate = tf.placeholder(tf.float32)    \n",
    "        \n",
    "        with slim.arg_scope(nets.inception.inception_v1_arg_scope()):\n",
    "            net, endpoints = nets.inception.inception_v1(self.X, num_classes=1001)        \n",
    "            # 在这里，我们直接使用预置的模型。\n",
    "        net = endpoints['Mixed_5c']\n",
    "        net = tf.reduce_mean(net, [1, 2], keep_dims=True, name='global_pool')\n",
    "        net = tf.reshape(net , [-1, 1024])\n",
    "        # 下面这些，大家应该非常熟悉了，和MNIST的一样的\n",
    "        net = tf.nn.dropout(net, self.dropRate)\n",
    "        logits = tf.layers.dense(net, 17, use_bias=True,\n",
    "                                 kernel_initializer=tf.constant_initializer(0),\n",
    "                                 bias_initializer=tf.constant_initializer(0))\n",
    "        self.logits = logits\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.y, logits=logits)\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss)\n",
    "        \n",
    "        # 用于模型训练\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.y, axis=1), tf.argmax(logits, axis=1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        \n",
    "#         用于保存训练好的模型\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "        summary_loss = tf## 标题 ##.summary.scalar('loss', self.loss)\n",
    "        summary_accuracy = tf.summary.scalar('accuracy', self.accuracy)\n",
    "        self.merged_summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    def read_image_label_list(self, name_list):\n",
    "        # 读取图像文件和标注列表\n",
    "        \n",
    "        img_list=[]\n",
    "        label_list=[]\n",
    "                \n",
    "        with open(name_list) as fr:\n",
    "            for line in fr.readlines():\n",
    "                imgIndex = int(line.strip())\n",
    "                imgLabel = int(imgIndex / 80)\n",
    "                imgPath = 'data/jpg/image_%04d.jpg' % imgIndex\n",
    "                img_list.append(imgPath)                \n",
    "                label_list.append(imgLabel)                \n",
    "\n",
    "        return img_list, label_list      \n",
    "\n",
    "    def read_file(self, name_list):\n",
    "        image_list, label_list = self.read_image_label_list(name_list)\n",
    "        imagepaths, labels = tf.train.slice_input_producer([image_list, label_list], shuffle=True)\n",
    "        image = tf.read_file(imagepaths)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize_images(image, [224, 224])\n",
    "        image = tf.image.random_brightness(image, 15)\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = (image * 1.0 / 127.5 - 1)\n",
    "        label = tf.one_hot(labels, 17)\n",
    "        X, Y = tf.train.batch([image, label], batch_size=self.batch_size, num_threads=2, capacity=self.batch_size*4)    \n",
    "        return X, Y\n",
    "    def train(self):\n",
    "        training_images, training_labels = self.read_file('trn1.txt')\n",
    "        test_images, test_labels = self.read_file('val1.txt')\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)      \n",
    "            variables_to_restore = slim.get_variables_to_restore()\n",
    "            init_fn = slim.assign_from_checkpoint_fn(r'pre_trained/inception_v1.ckpt',\n",
    "                                         variables_to_restore,\n",
    "                                         ignore_missing_vars=True)\n",
    "            init_fn(sess)\n",
    "            \n",
    "            summary_writer = tf.summary.FileWriter('log/train_base', sess.graph)\n",
    "            summary_writer_test = tf.summary.FileWriter('log/test_base')\n",
    "\n",
    "            for i in range(self.iter_num):   \n",
    "                tf.local_variables_initializer().run()\n",
    "                images, labels = sess.run([training_images, training_labels])  \n",
    "               \n",
    "                feed_dict = {self.dropRate: 0.5,\n",
    "                         self.X :images,\n",
    "                         self.y :labels}           \n",
    "                loss, _ = sess.run([self.loss, self.train_step], \n",
    "                                  feed_dict=feed_dict)   # 每调用一次sess.run，就像拧开水管一样，所有self.loss和self.train_step涉及到的运算都会被调用一次。\n",
    "\n",
    "                if i%10 ==0:\n",
    "                    images, labels = sess.run([training_images, training_labels]) \n",
    "                    train_accuracy, summary_str = sess.run([self.accuracy,self.merged_summary_op], feed_dict={self.X: images, self.y: labels, self.dropRate: 1.})  # 把训练集数据装填进去\n",
    "                    summary_writer.add_summary(summary_str, i)   \n",
    "                    images, labels = sess.run([test_images, test_labels])\n",
    "                    test_accuracy, summary_str = sess.run([self.accuracy,self.merged_summary_op], feed_dict={self.X: images, self.y: labels, self.dropRate: 1.})  # 把测试集数据装填进去\n",
    "                    summary_writer_test.add_summary(summary_str, i)\n",
    "                    print ('iter\\t%i\\tloss\\t%f\\ttrain_accuracy\\t%f\\ttest_accuracy\\t%f' % (i,loss,train_accuracy, test_accuracy))\n",
    "\n",
    "            self.saver.save(sess, 'model/flowerModel') # 保存模型\n",
    "            summary_writer.flush()\n",
    "            summary_writer_test.flush()\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "            \n",
    "    def test(self):\n",
    "        test_images, test_labels = self.read_file('tst1.txt')\n",
    "        with tf.Session() as sess:\n",
    "            self.saver.restore(sess, 'model/flowerModel')\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess=sess, coord=coord)     \n",
    "            Accuracy = []\n",
    "            for i in range(int(340/self.batch_size) + 1):\n",
    "                images, labels = sess.run([test_images, test_labels])\n",
    "                test_accuracy = sess.run(self.accuracy, feed_dict={self.X: images, self.y: labels, self.dropRate: 1.})  # 把测试集数据装填进去\n",
    "                Accuracy.append(test_accuracy)\n",
    "            print('==' * 15) \n",
    "            print( 'Test Accuracy: ', np.mean(np.array(Accuracy))   ) \n",
    "            coord.request_stop()\n",
    "            coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-7d438a9b8235>:18: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/rollo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/losses/losses_impl.py:731: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trn1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-636dbf0381ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7d438a9b8235>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trn1.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val1.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7d438a9b8235>\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(self, name_list)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image_label_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mimagepaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagepaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7d438a9b8235>\u001b[0m in \u001b[0;36mread_image_label_list\u001b[0;34m(self, name_list)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mlabel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mimgIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trn1.txt'"
     ]
    }
   ],
   "source": [
    "model = GoogLeNet(0.1, 50, 500)\n",
    "model.train()\n",
    "model.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
