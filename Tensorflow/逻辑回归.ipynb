{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 4)\n",
      "(50, 4)\n",
      "(99, 3)\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "iris_X, iris_y = iris.data[:-1,:], iris.target[:-1]\n",
    "\n",
    "iris_y= pd.get_dummies(iris_y).values\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(iris_X, iris_y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(trainX.shape)\n",
    "\n",
    "print(testX.shape)\n",
    "\n",
    "print(trainY.shape)\n",
    "\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numFeatures是我们输入数据中的特征数量。\n",
    "\n",
    "# 在iris数据集中，这个数字是'4'\n",
    "\n",
    "numFeatures = trainX.shape[1]\n",
    "\n",
    "# numLabels使我们数据集的类的数量\n",
    "\n",
    "# 在iris数据集中，这个数字是'3'\n",
    "\n",
    "numLabels = trainY.shape[1]\n",
    "\n",
    "# 占位符\n",
    "\n",
    "# 'None' 意味着TensorFlow不应该期望在该维度中有一个固定的数字\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, numFeatures]) # Iris 有4个特征，所以X是来保存我们的数据的张量\n",
    "\n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels]) # 这将是我们的3个类矩阵的正确答案\n",
    "\n",
    "W = tf.Variable(tf.zeros([4, 3]))  # 4维输入和3个类\n",
    "\n",
    "b = tf.Variable(tf.zeros([3])) # 3维输出 [0,0,1],[0,1,0],[1,0,0]\n",
    "\n",
    "#随机抽取标准偏差为.01的正态分布\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=0.01,\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=0.01,\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic回归方程的三要素分解\n",
    "\n",
    "# 注意这些feed到其他\n",
    "\n",
    "apply_weights_OP = tf.matmul(X, weights, name=\"apply_weights\")\n",
    "\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "\n",
    "# 激励函数\n",
    "# activation_OP = tf.nn.relu(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.relu6(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.elu(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.softplus(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.softsign(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.dropout(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.bias_add(add_bias_OP, name=\"activation\")\n",
    "activation_OP = tf.nn.tanh(add_bias_OP, name=\"activation\")\n",
    "# activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们训练中的Epochs数\n",
    "\n",
    "numEpochs = 700\n",
    "\n",
    "# 定义我们的学习率迭代 (衰减)\n",
    "\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=trainX.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义我们的成本函数 - 平方均值误差\n",
    "\n",
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")\n",
    "\n",
    "#定义我们的渐变下降\n",
    "# training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)\n",
    "# training_OP = tf.train.AdadeltaOptimizer(learningRate).minimize(cost_OP)\n",
    "# training_OP = tf.train.AdagradOptimizerlearningRate).minimize(cost_OP)\n",
    "# training_OP = tf.train.MomentumOptimizer(learningRate).minimize(cost_OP)\n",
    "training_OP = tf.train.AdamOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个tensorflow会话\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# 初始化我们的权重和偏差变量\n",
    "\n",
    "init_OP = tf.global_variables_initializer()\n",
    "\n",
    "# 初始化所有tensorflow变量\n",
    "\n",
    "sess.run(init_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmax(activation_OP, 1)以最大概率返回标签\n",
    "\n",
    "# argmax(yGold, 1)是正确的标签\n",
    "\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "\n",
    "# 如果每个错误预测为0并且每个真实预测为1，则平均值会返回我们的准确性\n",
    "\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "\n",
    "# 汇总op的回归输出\n",
    "\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "\n",
    "# 汇总op的准确度\n",
    "\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "\n",
    "# 汇总op的成本\n",
    "\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "\n",
    "# 汇总检查每次迭代后变量(W, b) 是如何更新\n",
    "\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "\n",
    "# 合并所有的汇总\n",
    "\n",
    "merged = tf.summary.merge([activation_summary_OP, accuracy_summary_OP, cost_summary_OP, weightSummary, biasSummary])\n",
    "\n",
    "# 汇总writer\n",
    "\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.313131, cost 49.0531, change in cost 49.0531\n",
      "step 100, training accuracy 0.686869, cost 25.1193, change in cost 23.9338\n",
      "step 200, training accuracy 0.676768, cost 21.1163, change in cost 4.003\n",
      "step 300, training accuracy 0.686869, cost 19.6503, change in cost 1.46595\n",
      "step 400, training accuracy 0.676768, cost 19.0298, change in cost 0.620533\n",
      "step 500, training accuracy 0.707071, cost 18.6869, change in cost 0.342886\n",
      "step 600, training accuracy 0.717172, cost 18.4458, change in cost 0.241039\n",
      "final accuracy on test set: 0.76\n"
     ]
    }
   ],
   "source": [
    "# 初始化报告变量\n",
    "\n",
    "cost = 0\n",
    "\n",
    "diff = 1\n",
    "\n",
    "epoch_values = []\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "cost_values = []\n",
    "\n",
    "# 训练 epochs\n",
    "\n",
    "for i in range(numEpochs):\n",
    "\n",
    "    if i > 1 and diff < .0001:\n",
    "\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "\n",
    "        break\n",
    "\n",
    "    else:\n",
    "\n",
    "        # 运行训练\n",
    "\n",
    "        step = sess.run(training_OP, feed_dict={X: trainX, yGold: trainY})\n",
    "\n",
    "        # Report occasional stats\n",
    "\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            # 将epoch添加到epoch_values\n",
    "\n",
    "            epoch_values.append(i)\n",
    "\n",
    "            # 基于测试集数据生成准确度\n",
    "\n",
    "            train_accuracy, newCost = sess.run([accuracy_OP, cost_OP], feed_dict={X: trainX, yGold: trainY})\n",
    "\n",
    "            # 为实时图形变量添加准确性\n",
    "\n",
    "            accuracy_values.append(train_accuracy)\n",
    "\n",
    "            # 为实时图形变量添加成本\n",
    "\n",
    "            cost_values.append(newCost)\n",
    "\n",
    "            # 对变量重新分配值\n",
    "\n",
    "            diff = abs(newCost - cost)\n",
    "\n",
    "            cost = newCost\n",
    "\n",
    "            #生成输出语句\n",
    "\n",
    "            print(\"step %d, training accuracy %g, cost %g, change in cost %g\"%(i, train_accuracy, newCost, diff))\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP,\n",
    "                                                     feed_dict={X: testX,\n",
    "                                                                yGold: testY})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
