{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable( tf.constant(0.1, shape=shape))\n",
    "\n",
    "def conv2D(x, W):\n",
    "    # padding:在卷积核移动逐渐扫描整体图时候，因为步长的设置问题，可能导致剩下未扫描的空间不足以提供给卷积核的大小扫描 \n",
    "    # 比如有图大小为5*5,卷积核为2*2,步长为2,卷积核扫描了两次后，剩下一个元素，不够卷积核扫描了.\n",
    "    # 这个时候就在后面补零，补完后满足卷积核的扫描，这种方式就是same。如果说把刚才不足以扫描的元素位置抛弃掉，就是valid方式\n",
    "    # strides: 第一个和第四个必须为1，如果步长为2.，就是[1,2,2,1]\n",
    "    # default format \"NHWC\", the data is stored in the order of: [batch, height, width, channels].\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# 自己实现一个next_batch方法\n",
    "def next_batch(train_data, train_target, batch_size):\n",
    "    # 获取所有的索引\n",
    "    idx = [ i for i in range(0, len(train_target))]\n",
    "    # 打乱索引\n",
    "    np.random.shuffle(idx)\n",
    "    batch_data = []\n",
    "    batch_target = []\n",
    "    # 从打乱的索引中取出batch_size个，加入data和target\n",
    "    for i in range(0, batch_size):\n",
    "        batch_data.append(train_data[idx[i]])\n",
    "        batch_target.append(train_target[idx[i]])\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 初始化参数\n",
    "mnist = input_data.read_data_sets(\"./MNIST_DATA\", one_hot=True)\n",
    "train_data = mnist.train.images #55000的数据量\n",
    "train_target = mnist.train.labels\n",
    "test_data = mnist.test.images #10000数据\n",
    "test_target = mnist.test.labels\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y = tf.placeholder(\"float\", shape=[None, 10])\n",
    "keep_prob = tf.placeholder(\"float\") # 隐藏节点保持工作的概率\n",
    "epochs_num = 5000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积\n",
    "# 卷积核大小5x5，32个卷积核（卷积核的每次滑动都会有一个5x5项的线性组合，若干次滑遍28x28的图像，产生一个28x28的新图像），所以传出32张图像（通道）。\n",
    "# 直观来讲，这里就比较像一张图片加了32种滤镜，滤出32中特征供后续使用\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "# 因为卷积核有32个，就有32个线性组合，所以需要32个截距\n",
    "# 需要注意一点的是，每一次卷积操作，要所有通道（也就是等于原图的厚度）计算完毕后并再进行截距修正，相当于综合了每一个通道的截距\n",
    "b_conv1 = bias_variable([32])\n",
    "# 输入图像是28像素×28像素，1个通道（灰度）。在这种情况下，第一个维度是图像的批次编号，可以是任意大小（因此我们将其设置为-1）。\n",
    "# 第二和第三个维度是宽度和高度，最后一个是图像通道。我们按照这种方式把图片化成标准网络的输入参数。\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# Relu激活，这里就很像线性组合了:XW + b。因为Padding是SAME，所以仍然是28x28\n",
    "h_conv1 = tf.nn.relu(conv2D(x_image, W_conv1) + b_conv1)\n",
    "# 池化，压缩图片，提取特征，池化方法选择max_pool。这里变成了14x14\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二层卷积\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "# 这里就是32次线性组合之后加入一个bias，64个核一共进行64*32次线性组合，最后生成64个通道\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2D(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2) # 这里变成了7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建CNN的第一个全连接层\n",
    "# 我们设置第一个隐藏层（全连接层）有1024个神经元，每个神经元的连线数量为flatten图像tensor的数量，即7x7的图像再乘以64个滤镜\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "# 每个神经元都要有一个bias\n",
    "b_fc1 = bias_variable([1024])\n",
    "# 将原有图像，变成一行，7*7*64列的向量\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "# 全连接层仍然用Relu激活函数\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 失活一部分节点，提升速度，防止过拟合\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建CNN的第二个全连接层\n",
    "# 1024个神经元要到10个分类\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "# 只有10个输出神经元，自然只有10个截距\n",
    "b_fc2 = bias_variable([10])\n",
    "# 最后一次线性组合后，激活函数采用softmax，这个是多元分类常用的激活函数\n",
    "# 假设10个神经元的输出为a0,a2,...,a9, 那么激活函数为 S_i = e^{ai} / (e^{a1} + e^{a2} + ... + e^{a9})\n",
    "y_conv = tf.nn.softmax( tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.120\n",
      "step 100, train accuracy 0.890\n",
      "step 200, train accuracy 0.940\n",
      "step 300, train accuracy 0.930\n",
      "step 400, train accuracy 0.950\n",
      "step 500, train accuracy 0.940\n",
      "step 600, train accuracy 0.970\n",
      "step 700, train accuracy 0.960\n",
      "step 800, train accuracy 0.950\n",
      "step 900, train accuracy 0.970\n",
      "step 1000, train accuracy 0.980\n",
      "step 1100, train accuracy 1.000\n",
      "step 1200, train accuracy 1.000\n",
      "step 1300, train accuracy 0.980\n",
      "step 1400, train accuracy 0.970\n",
      "step 1500, train accuracy 0.990\n",
      "step 1600, train accuracy 0.990\n",
      "step 1700, train accuracy 0.990\n",
      "step 1800, train accuracy 1.000\n",
      "step 1900, train accuracy 1.000\n",
      "step 2000, train accuracy 0.970\n",
      "step 2100, train accuracy 1.000\n",
      "step 2200, train accuracy 0.990\n",
      "step 2300, train accuracy 0.980\n",
      "step 2400, train accuracy 0.980\n",
      "step 2500, train accuracy 1.000\n",
      "step 2600, train accuracy 0.980\n",
      "step 2700, train accuracy 0.980\n",
      "step 2800, train accuracy 1.000\n",
      "step 2900, train accuracy 0.980\n",
      "step 3000, train accuracy 0.980\n",
      "step 3100, train accuracy 0.990\n",
      "step 3200, train accuracy 1.000\n",
      "step 3300, train accuracy 0.980\n",
      "step 3400, train accuracy 1.000\n",
      "step 3500, train accuracy 1.000\n",
      "step 3600, train accuracy 0.990\n",
      "step 3700, train accuracy 1.000\n",
      "step 3800, train accuracy 0.980\n",
      "step 3900, train accuracy 0.980\n",
      "step 4000, train accuracy 1.000\n",
      "step 4100, train accuracy 0.990\n",
      "step 4200, train accuracy 0.990\n",
      "step 4300, train accuracy 0.990\n",
      "step 4400, train accuracy 0.990\n",
      "step 4500, train accuracy 1.000\n",
      "step 4600, train accuracy 1.000\n",
      "step 4700, train accuracy 1.000\n",
      "step 4800, train accuracy 1.000\n",
      "step 4900, train accuracy 1.000\n",
      "Training Finished\n",
      "Test accuracy 1.000\n"
     ]
    }
   ],
   "source": [
    "# 创建一个Session\n",
    "sess = tf.InteractiveSession()\n",
    "# 损失函数用交叉熵\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(y_conv))\n",
    "# 训练函数用Adam,使交叉熵最小\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# 预测\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, axis=1), tf.argmax(y,axis=1))\n",
    "# 因为都是1或者0，均值就是准确率了\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "# 运行初始化所有变量\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 循环5000次进行训练\n",
    "for i in range(epochs_num):\n",
    "    batch_data, batch_target = next_batch(train_data, train_target, batch_size)\n",
    "    # 每100次展示下准确率\n",
    "    if i %100 == 0:\n",
    "        # 这一次一个也不失活\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_data, y:batch_target, keep_prob: 1.0})\n",
    "        print(\"step %d, train accuracy %.3f\" %(i, train_accuracy))\n",
    "    # 失活一半\n",
    "    train_step.run(feed_dict={x:batch_data, y:batch_target, keep_prob: 0.5})\n",
    "\n",
    "#训练全部完成后\n",
    "print(\"Training Finished\")\n",
    "print(\"Test accuracy %.3f\"%accuracy.eval(feed_dict={x:batch_data, y:batch_target, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function run in module tensorflow.python.client.session:\n",
      "\n",
      "run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "    Runs operations and evaluates tensors in `fetches`.\n",
      "    \n",
      "    This method runs one \"step\" of TensorFlow computation, by\n",
      "    running the necessary graph fragment to execute every `Operation`\n",
      "    and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "    `feed_dict` for the corresponding input values.\n",
      "    \n",
      "    The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "    nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "    elements at its leaves.  A graph element can be one of the following types:\n",
      "    \n",
      "    * An @{tf.Operation}.\n",
      "      The corresponding fetched value will be `None`.\n",
      "    * A @{tf.Tensor}.\n",
      "      The corresponding fetched value will be a numpy ndarray containing the\n",
      "      value of that tensor.\n",
      "    * A @{tf.SparseTensor}.\n",
      "      The corresponding fetched value will be a\n",
      "      @{tf.SparseTensorValue}\n",
      "      containing the value of that sparse tensor.\n",
      "    * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "      numpy ndarray containing the handle of that tensor.\n",
      "    * A `string` which is the name of a tensor or operation in the graph.\n",
      "    \n",
      "    The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "    where the leaves are replaced by the corresponding values returned by\n",
      "    TensorFlow.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "    ```python\n",
      "       a = tf.constant([10, 20])\n",
      "       b = tf.constant([1.0, 2.0])\n",
      "       # 'fetches' can be a singleton\n",
      "       v = session.run(a)\n",
      "       # v is the numpy array [10, 20]\n",
      "       # 'fetches' can be a list.\n",
      "       v = session.run([a, b])\n",
      "       # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "       # 1-D array [1.0, 2.0]\n",
      "       # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "       MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "       v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "       # v is a dict with\n",
      "       # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "       # 'b' (the numpy array [1.0, 2.0])\n",
      "       # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "       # [10, 20].\n",
      "    ```\n",
      "    \n",
      "    The optional `feed_dict` argument allows the caller to override\n",
      "    the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "    one of the following types:\n",
      "    \n",
      "    * If the key is a @{tf.Tensor}, the\n",
      "      value may be a Python scalar, string, list, or numpy ndarray\n",
      "      that can be converted to the same `dtype` as that\n",
      "      tensor. Additionally, if the key is a\n",
      "      @{tf.placeholder}, the shape of\n",
      "      the value will be checked for compatibility with the placeholder.\n",
      "    * If the key is a\n",
      "      @{tf.SparseTensor},\n",
      "      the value should be a\n",
      "      @{tf.SparseTensorValue}.\n",
      "    * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "      should be a nested tuple with the same structure that maps to their\n",
      "      corresponding values as above.\n",
      "    \n",
      "    Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "    of the corresponding key.\n",
      "    \n",
      "    The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "    allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "    on).\n",
      "    \n",
      "    The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "    appropriate, the non-Tensor output of this step will be collected there. For\n",
      "    example, when users turn on tracing in `options`, the profiled info will be\n",
      "    collected into this argument and passed back.\n",
      "    \n",
      "    Args:\n",
      "      fetches: A single graph element, a list of graph elements,\n",
      "        or a dictionary whose values are graph elements or lists of graph\n",
      "        elements (described above).\n",
      "      feed_dict: A dictionary that maps graph elements to values\n",
      "        (described above).\n",
      "      options: A [`RunOptions`] protocol buffer\n",
      "      run_metadata: A [`RunMetadata`] protocol buffer\n",
      "    \n",
      "    Returns:\n",
      "      Either a single value if `fetches` is a single graph element, or\n",
      "      a list of values if `fetches` is a list, or a dictionary with the\n",
      "      same keys as `fetches` if that is a dictionary (described above).\n",
      "    \n",
      "    Raises:\n",
      "      RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "        closed).\n",
      "      TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "      ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "        `Tensor` that doesn't exist.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(accuracy.eval)\n",
    "help(tf.Session.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d in module tensorflow.python.layers.convolutional:\n",
      "\n",
      "conv2d(inputs, filters, kernel_size, strides=(1, 1), padding='valid', data_format='channels_last', dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer=None, bias_initializer=<tensorflow.python.ops.init_ops.Zeros object at 0x7f02df6c2588>, kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, trainable=True, name=None, reuse=None)\n",
      "    Functional interface for the 2D convolution layer.\n",
      "    \n",
      "    This layer creates a convolution kernel that is convolved\n",
      "    (actually cross-correlated) with the layer input to produce a tensor of\n",
      "    outputs. If `use_bias` is True (and a `bias_initializer` is provided),\n",
      "    a bias vector is created and added to the outputs. Finally, if\n",
      "    `activation` is not `None`, it is applied to the outputs as well.\n",
      "    \n",
      "    Arguments:\n",
      "      inputs: Tensor input.\n",
      "      filters: Integer, the dimensionality of the output space (i.e. the number\n",
      "        of filters in the convolution).\n",
      "      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      "        height and width of the 2D convolution window.\n",
      "        Can be a single integer to specify the same value for\n",
      "        all spatial dimensions.\n",
      "      strides: An integer or tuple/list of 2 integers,\n",
      "        specifying the strides of the convolution along the height and width.\n",
      "        Can be a single integer to specify the same value for\n",
      "        all spatial dimensions.\n",
      "        Specifying any stride value != 1 is incompatible with specifying\n",
      "        any `dilation_rate` value != 1.\n",
      "      padding: One of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      "      data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
      "        The ordering of the dimensions in the inputs.\n",
      "        `channels_last` corresponds to inputs with shape\n",
      "        `(batch, height, width, channels)` while `channels_first` corresponds to\n",
      "        inputs with shape `(batch, channels, height, width)`.\n",
      "    \n",
      "      dilation_rate: An integer or tuple/list of 2 integers, specifying\n",
      "        the dilation rate to use for dilated convolution.\n",
      "        Can be a single integer to specify the same value for\n",
      "        all spatial dimensions.\n",
      "        Currently, specifying any `dilation_rate` value != 1 is\n",
      "        incompatible with specifying any stride value != 1.\n",
      "      activation: Activation function. Set it to None to maintain a\n",
      "        linear activation.\n",
      "      use_bias: Boolean, whether the layer uses a bias.\n",
      "      kernel_initializer: An initializer for the convolution kernel.\n",
      "      bias_initializer: An initializer for the bias vector. If None, the default\n",
      "        initializer will be used.\n",
      "      kernel_regularizer: Optional regularizer for the convolution kernel.\n",
      "      bias_regularizer: Optional regularizer for the bias vector.\n",
      "      activity_regularizer: Optional regularizer function for the output.\n",
      "      kernel_constraint: Optional projection function to be applied to the\n",
      "          kernel after being updated by an `Optimizer` (e.g. used to implement\n",
      "          norm constraints or value constraints for layer weights). The function\n",
      "          must take as input the unprojected variable and must return the\n",
      "          projected variable (which must have the same shape). Constraints are\n",
      "          not safe to use when doing asynchronous distributed training.\n",
      "      bias_constraint: Optional projection function to be applied to the\n",
      "          bias after being updated by an `Optimizer`.\n",
      "      trainable: Boolean, if `True` also add variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "      name: A string, the name of the layer.\n",
      "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
      "        by the same name.\n",
      "    \n",
      "    Returns:\n",
      "      Output tensor.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: if eager execution is enabled.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.layers.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
